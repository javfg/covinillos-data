{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv\"\n",
    "data_spain_path = \"./spain_timeseries.csv\"\n",
    "recovered_jhu_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\"\n",
    "events_url = \"https://raw.githubusercontent.com/javfg/covinillos-data/master/events.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_url).fillna(0)\n",
    "data_spain = pd.read_csv(data_spain_path)\n",
    "recovered_data = pd.read_csv(recovered_jhu_url)\n",
    "events = pd.read_csv(events_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix JHU recovered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill N/As, remove geo coordinates columns, aggregate by country\n",
    "recovered_total = recovered_data.fillna(0).drop(['Lat', 'Long'], axis=1).groupby(\"Country/Region\").sum()\n",
    "\n",
    "# fix date format\n",
    "recovered_total.columns = [str(datetime.strptime(x, \"%m/%d/%y\").date()) for x in list(recovered_total.columns)]\n",
    "\n",
    "# fix column names and some country names\n",
    "recovered_total.index.names = [\"location\"]\n",
    "recovered_total = recovered_total.rename(index={'Country/Region': 'location', 'US': 'United States'})\n",
    "\n",
    "# calculate daily cases\n",
    "recovered_daily = recovered_total.diff(axis=1).fillna(recovered_total).clip(lower=0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get or zero function for JHU data: returns value for a country/date or 0 if non-existant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goz(df, country, date):\n",
    "    result = 0\n",
    "    try:\n",
    "        result = df.loc[country][date]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "countries = list(data['location'].unique())\n",
    "countries.remove('Spain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(country, date):\n",
    "    return events.loc[(events.country == country) & (events.date == date)][['description', 'group', 'reference']].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    dataset[country] = []\n",
    "\n",
    "    for date in list(data.loc[data['location'] == country]['date'].unique()):\n",
    "        day_data = data.loc[(data['location'] == country) & (data['date'] == date)]\n",
    "\n",
    "        dataset[country].append({\n",
    "            'date': date,\n",
    "            'confirmed_total': int(day_data['total_cases']),\n",
    "            'deaths_total': int(day_data['total_deaths']),\n",
    "            'recovered_total': int(goz(recovered_total, country, date)),\n",
    "            'confirmed_daily': int(day_data['new_cases']),\n",
    "            'deaths_daily': int(day_data['new_deaths']),\n",
    "            'recovered_daily': int(goz(recovered_daily, country, date)),\n",
    "            'confirmed_pm_total': int(day_data['total_cases_per_million']),\n",
    "            'confirmed_pm_daily': int(day_data['new_cases_per_million']),\n",
    "            'deaths_pm_total': int(day_data['total_deaths_per_million']),\n",
    "            'deaths_pm_daily': int(day_data['new_deaths_per_million']),\n",
    "            # 'tests_total': int(day_data['total_tests']),\n",
    "            # 'tests_daily': int(day_data['new_tests']),\n",
    "            # 'tests_pt_total': int(day_data['total_tests_per_thousand']),\n",
    "            # 'tests_pt_daily': int(day_data['new_tests_per_thousand']),\n",
    "            'events': get_events(country, date)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day(day):\n",
    "    day_dict = day.to_dict()\n",
    "    day_dict['events'] = get_events('Spain', day_dict['date'])\n",
    "    spain.append(day_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain = []\n",
    "data_spain.apply(add_day, axis=1);\n",
    "dataset['Spain'] = spain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reduce size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = {}\n",
    "\n",
    "for (country, data) in dataset.items():\n",
    "    small_dataset[country] = []\n",
    "    \n",
    "    for (index, day) in enumerate(data):\n",
    "        small_dataset[country].append({\n",
    "            'date': day['date'],\n",
    "            'data': [val for (key, val) in day.items() if key not in ['date', 'events']]\n",
    "        })\n",
    "\n",
    "        if len(day['events']):\n",
    "            small_dataset[country][index]['events'] = day['events']   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./data/dataset.json\", \"w\") as data_file:\n",
    "    json.dump(small_dataset, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./data/events.json\", \"w\") as events_file:\n",
    "    json.dump(events.to_dict(orient=\"records\"), events_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}